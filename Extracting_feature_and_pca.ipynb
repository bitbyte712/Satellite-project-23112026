{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGP_xSQXUBEI",
        "outputId": "fca298d7-9586-45e1-c269-881c98848690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXTRACTING FEATURE AND PCA"
      ],
      "metadata": {
        "id": "MZW4JhrAGn0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/images\"\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "img_path = os.path.join(IMAGES_PATH, \"15000.png\")\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "img_tensor = image_transform(img)\n",
        "\n",
        "print(\"Tensor shape:\", img_tensor.shape)\n",
        "print(\"Min/Max:\", img_tensor.min().item(), img_tensor.max().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eOGprkTXev0",
        "outputId": "b51a13a3-5970-4537-c2cb-7a682a37167a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: torch.Size([3, 224, 224])\n",
            "Min/Max: 0.0470588244497776 0.9803921580314636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDVskF2Mb5HH",
        "outputId": "f8a7110d-15a5-4a9c-b6cc-a9ef881c00ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 165MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (5): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (6): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (7): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "img = Image.open(os.path.join(IMAGES_PATH, \"15000.png\")).convert(\"RGB\")\n",
        "img_tensor = image_transform(img).unsqueeze(0).to(device)  # add batch dim\n",
        "\n",
        "with torch.no_grad():\n",
        "    features = resnet(img_tensor)\n",
        "\n",
        "print(\"Raw feature shape:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsWTnt0UcD5e",
        "outputId": "cf6826b1-a2a3-454e-c2c4-7b3e3282d9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw feature shape: torch.Size([1, 2048, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = features.view(features.size(0), -1)\n",
        "print(\"Flattened shape:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfTnRJmJcONF",
        "outputId": "db3118e2-0135-49a5-d427-392dddb707e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened shape: torch.Size([1, 2048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_features.npy\"\n",
        "\n",
        "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# image transform\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# load pretrained ResNet50 (feature extractor)\n",
        "import torchvision.models as models\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # remove classifier\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "# total images\n",
        "N_IMAGES = 16209\n",
        "\n",
        "# storage\n",
        "features_all = np.zeros((N_IMAGES, 2048), dtype=np.float32)\n",
        "\n",
        "# extraction loop\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(N_IMAGES), desc=\"Extracting CNN features\"):\n",
        "        img_path = os.path.join(IMAGES_PATH, f\"{i}.png\")\n",
        "\n",
        "        # load image\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = image_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "        # forward pass\n",
        "        feats = resnet(img_tensor)          # [1, 2048, 1, 1]\n",
        "        feats = feats.view(-1).cpu().numpy()  # [2048]\n",
        "\n",
        "        features_all[i] = feats\n",
        "\n",
        "# save to disk\n",
        "np.save(SAVE_PATH, features_all)\n",
        "\n",
        "print(\"Saved CNN features to:\", SAVE_PATH)\n",
        "print(\"Final shape:\", features_all.shape)\n"
      ],
      "metadata": {
        "id": "pbf4jNBZzBuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import torchvision.models as models\n",
        "\n",
        "# PATHS\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_features.npy\"\n",
        "\n",
        "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)\n",
        "\n",
        "#  DEVICE\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#  IMAGE TRANSFORM\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#  LOAD RESNET50\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # remove classifier\n",
        "resnet = resnet.to(device)\n",
        "resnet.eval()\n",
        "\n",
        "\n",
        "N_IMAGES = 16209\n",
        "FEATURE_DIM = 2048\n",
        "\n",
        "features_all = np.zeros((N_IMAGES, FEATURE_DIM), dtype=np.float32)\n",
        "bad_images = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(N_IMAGES), desc=\"Extracting CNN features\"):\n",
        "        img_path = os.path.join(IMAGES_PATH, f\"{i}.png\")\n",
        "\n",
        "        try:\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "            img_tensor = image_transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "            feats = resnet(img_tensor)\n",
        "            feats = feats.view(-1).cpu().numpy()\n",
        "\n",
        "            features_all[i] = feats\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            bad_images.append(i)\n",
        "            features_all[i] = np.zeros(FEATURE_DIM, dtype=np.float32)\n",
        "            print(f\"⚠️ Skipped corrupted image: {i}.png | Error: {e}\")\n",
        "\n",
        "# ================= SAVE =================\n",
        "np.save(SAVE_PATH, features_all)\n",
        "\n",
        "print(\"Saved CNN features to:\", SAVE_PATH)\n",
        "print(\"Final feature shape:\", features_all.shape)\n",
        "print(\"Total corrupted images:\", len(bad_images))\n",
        "print(\"Corrupted image indices:\", bad_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unhx3cKckkIU",
        "outputId": "ac9acd54-ce7a-4b38-8fc4-d98c7e060ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting CNN features:   0%|          | 8/16209 [00:00<03:38, 74.25it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Skipped corrupted image: 9.png | Error: cannot identify image file '/content/drive/MyDrive/IITR/Satellite-project/images/9.png'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting CNN features: 100%|██████████| 16209/16209 [3:02:27<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved CNN features to: /content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_features.npy\n",
            "Final feature shape: (16209, 2048)\n",
            "Total corrupted images: 1\n",
            "Corrupted image indices: [9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# load CNN features\n",
        "FEATURE_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_features.npy\"\n",
        "X_img = np.load(FEATURE_PATH)\n",
        "\n",
        "print(\"Original shape:\", X_img.shape)\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=64, random_state=42)\n",
        "X_img_pca = pca.fit_transform(X_img)\n",
        "\n",
        "print(\"PCA shape:\", X_img_pca.shape)\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_.sum())\n",
        "\n",
        "# save PCA features\n",
        "PCA_SAVE_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_pca64.npy\"\n",
        "np.save(PCA_SAVE_PATH, X_img_pca)\n",
        "\n",
        "print(\"Saved PCA features to:\", PCA_SAVE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6RLJOD2QCGg",
        "outputId": "08dab3a3-365b-4cb7-9302-0bd5704744c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (16209, 2048)\n",
            "PCA shape: (16209, 64)\n",
            "Explained variance ratio: 0.86724424\n",
            "Saved PCA features to: /content/drive/MyDrive/IITR/Satellite-project/image_features/resnet50_pca64.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-NocLkPdyUmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# save PCA object (MANDATORY)\n",
        "PCA_MODEL_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/models/image_pca.joblib\"\n",
        "joblib.dump(pca, PCA_MODEL_PATH)\n",
        "\n",
        "print(\"Saved PCA model to:\", PCA_MODEL_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOJYDHDnyUpa",
        "outputId": "96b7d434-a7ed-4d1f-9e26-598ba6b1f131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PCA model to: /content/drive/MyDrive/IITR/Satellite-project/models/image_pca.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# paths\n",
        "IMAGES_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/IITR/Satellite-project/image_features/interpretable_features.npy\"\n",
        "\n",
        "N_IMAGES = 16209\n",
        "\n",
        "# storage: [green, blue, edge_density, brightness]\n",
        "interp_features = np.zeros((N_IMAGES, 4), dtype=np.float32)\n",
        "\n",
        "bad_images = []\n",
        "\n",
        "for i in tqdm(range(N_IMAGES), desc=\"Extracting interpretable features\"):\n",
        "    img_path = os.path.join(IMAGES_PATH, f\"{i}.png\")\n",
        "\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # ---- GREEN & BLUE RATIO (HSV) ----\n",
        "        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "        # green mask\n",
        "        green_mask = cv2.inRange(hsv, (35, 40, 40), (85, 255, 255))\n",
        "        green_ratio = np.sum(green_mask > 0) / green_mask.size\n",
        "\n",
        "        # blue mask (water)\n",
        "        blue_mask = cv2.inRange(hsv, (90, 50, 50), (140, 255, 255))\n",
        "        blue_ratio = np.sum(blue_mask > 0) / blue_mask.size\n",
        "\n",
        "        # ---- EDGE DENSITY ----\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "        edge_density = np.sum(edges > 0) / edges.size\n",
        "\n",
        "        # ---- BRIGHTNESS ----\n",
        "        brightness = np.mean(gray) / 255.0\n",
        "\n",
        "        interp_features[i] = [\n",
        "            green_ratio,\n",
        "            blue_ratio,\n",
        "            edge_density,\n",
        "            brightness\n",
        "        ]\n",
        "\n",
        "    except Exception as e:\n",
        "        bad_images.append(i)\n",
        "        interp_features[i] = np.zeros(4)\n",
        "\n",
        "# save\n",
        "np.save(SAVE_PATH, interp_features)\n",
        "\n",
        "print(\"Saved interpretable features to:\", SAVE_PATH)\n",
        "print(\"Shape:\", interp_features.shape)\n",
        "print(\"Corrupted images handled:\", len(bad_images))\n"
      ],
      "metadata": {
        "id": "ZWg7IoRiDVH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBlCuKHfDVLb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}